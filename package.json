{
  "name": "docstring-gpt",
  "displayName": "Docstring-GPT",
  "description": "An extension to automaticially generate docstrings for functions and classes with AI.",
  "icon": "images/icon.png",
  "version": "0.0.5",
  "engines": {
    "vscode": "^1.93.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onLanguage:python"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "docstring-gpt.generateDocstring",
        "title": "Generate Docstring",
        "category": "Generate",
        "icon": {
          "light": "images/light_button.png",
          "dark": "images/dark_button.png"
        }
      },
      {
        "command": "docstring-gpt.ollamaChat",
        "title": "Ollama Chat",
        "category": "Chat",
        "icon": {
          "light": "images/chat_icon_light_mode.png",
          "dark": "images/chat_icon_dark_mode.png"
        }
      }
    ],
    "keybindings": [
      {
        "command": "docstring-gpt.generateDocstring",
        "key": "ctrl+shift+.",
        "mac": "cmd+shift+.",
        "when": "editorTextFocus"
      },
      {
        "command": "docstring-gpt.ollamaChat",
        "key": "ctrl+shift+l",
        "mac": "cmd+shift+l",
        "when": "editorTextFocus"
      }
    ],
    "menus": {
      "editor/title": [
        {
          "command": "docstring-gpt.generateDocstring",
          "group": "navigation",
          "when": "resourceLangId == python || resourceLangId == cpp || resourceLangId == c || resourceLangId == java || resourceLangId == javascript || resourceLangId == typescript || resourceLangId == typescriptreact"
        },
        {
          "command": "docstring-gpt.ollamaChat",
          "group": "navigation"
        }
      ]
    },
    "configuration": {
      "title": "Docstring-GPT",
      "properties": {
        "Docstring-GPT.systemPrompt": {
          "title": "System Prompt",
          "type":"string",
          "default": "You are a docstring content generator. You must:\n1. Generate ONLY ONE docstring\n3. Never generate multiple docstring variations\n4. Never include ANY explanatory text or metadata; ONLY include the docstring\n5. Never include the code\n6. Always start at column 0 (no leading spaces/indentation)\n7. If a function already has a docstring, attempt to improve it or correct mistakes\n8. Unless otherwise told to, NEVER use ANY documentation syntax or tags, including but not limited to:\n   - No single line comment markers (///, #, etc.)\n   - No XML tags (<summary>, <param>, <returns>)\n   - No JSDoc tags (@param, @returns)\n   - No restructuredText (:param:, :returns:)\n\nThe content structure is:\n1. Single-line summary\n2. Extended description (if needed)\n3. Parameters/Args section\n4. Returns section\n5. Raises/Throws/Exceptions section (if applicable)\n6. Examples section (if needed)\n\nFormat requirements:\n- Only indent nested content (parameter descriptions, etc.) with 4 spaces\n- Start all sections at column 0\n- Match type hints with language conventions\n- Maintain consistent spacing between sections",
          "markdownDescription": "Specifies the system prompt for Docstring-GPT. It is recomended to keep the default setting, with minor modifications."
        },
        "Docstring-GPT.documentationSpecification": {
          "title": "Docstring1 Specification",
          "type": "string",
          "default": "Generate a VSCode-compatible docstring following the language-specific format:\n- For Python: Use Google-style format\n- For JavaScript/TypeScript: Use JSDoc-compatible format\n- For C/C++: Use triple-slash compatible format",
          "markdownDescription": "Specifies the specification for the docstrings to follow."
        },
        "Docstring-GPT.llm.endpoint": {
          "title": "LLM Endpoint",
          "type": "string",
          "default": "http://localhost:11434/v1",
          "markdownDescription": "This is the endpoint for the LLM, to use Openai models, change this to \"https://api.openai.com/v1\""
        },
        "Docstring-GPT.llm.apikey": {
          "title": "LLM API key",
          "type": "string",
          "default": "ollama",
          "markdownDescription": "This is the API key for the LLM service, the default for this is the ollama api key. If you want to use Openai models, you must provide your unique Openai API key here."
        },
        "Docstring-GPT.llm.model": {
          "title": "LLM model name",
          "type": "string",
          "default": "llama3.1",
          "markdownDescription": "This is the name of the model that you would like to use. The default mode is llama3.1 self hosten on ollama. You can change this to any ollama models you have installed or any Openai models you would like."
        },
        "Docstring-GPT.advanced.temperature": {
          "title": "LLM Temperature",
          "type": "number",
          "default": 1,
          "markdownDescription": "Temperature for LLM. The lower the temperature, the less random and better the responses. The higher the temperature, the higher the randomness, and the worse the responses. 0 gives optimal responses, giving the same response every time, and 2 is the recomended temperature upper limit."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "npm run check-types && npm run lint && node esbuild.js",
    "watch": "npm-run-all -p watch:*",
    "watch:esbuild": "node esbuild.js --watch",
    "watch:tsc": "tsc --noEmit --watch --project tsconfig.json",
    "package": "npm run check-types && npm run lint && node esbuild.js --production",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "check-types": "tsc --noEmit",
    "lint": "eslint src",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/mocha": "^10.0.7",
    "@types/node": "20.x",
    "@types/vscode": "^1.93.0",
    "@typescript-eslint/eslint-plugin": "^8.3.0",
    "@typescript-eslint/parser": "^8.3.0",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.4.1",
    "esbuild": "^0.23.1",
    "eslint": "^9.9.1",
    "npm-run-all": "^4.1.5",
    "typescript": "^5.5.4"
  },
  "dependencies": {
    "marked": "^14.1.2",
    "openai": "^4.0.0"
  }
}
